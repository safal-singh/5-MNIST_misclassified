{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIGHTH.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ASSIGNMENT 5\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.activations import relu\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "251b92e2-4d1c-4095-b2f2-bc5144b34d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f80a0bb45c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "6a704105-d109-4940-df15-5c4aeab9d39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWeTG5HzbAg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=128)\n",
        "val_iterator = datagen.flow(X_test, Y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "e46e74a8-cfd9-4989-eecf-24f9e000a556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1498
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0622 18:28:33.507200 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0622 18:28:33.526131 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0622 18:28:33.530726 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0622 18:28:33.556205 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0622 18:28:33.556997 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0622 18:28:34.269212 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0622 18:28:34.342388 140193449035648 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "W0622 18:28:34.462548 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "353620bd-a29b-4496-f85d-2d2b63d7fc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=20, verbose=1, validation_data=val_iterator, validation_steps=len(val_iterator), \n",
        "                    callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0622 18:32:46.028546 140193449035648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0622 18:32:46.143184 140193449035648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 15s 32ms/step - loss: 0.5274 - acc: 0.8517 - val_loss: 0.1004 - val_acc: 0.9810\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2495 - acc: 0.9280 - val_loss: 0.0682 - val_acc: 0.9863\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1958 - acc: 0.9414 - val_loss: 0.0449 - val_acc: 0.9894\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1654 - acc: 0.9489 - val_loss: 0.0357 - val_acc: 0.9909\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1504 - acc: 0.9490 - val_loss: 0.0350 - val_acc: 0.9909\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1391 - acc: 0.9512 - val_loss: 0.0314 - val_acc: 0.9917\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1295 - acc: 0.9527 - val_loss: 0.0273 - val_acc: 0.9930\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1220 - acc: 0.9542 - val_loss: 0.0283 - val_acc: 0.9914\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1169 - acc: 0.9544 - val_loss: 0.0247 - val_acc: 0.9922\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1126 - acc: 0.9545 - val_loss: 0.0218 - val_acc: 0.9934\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1089 - acc: 0.9557 - val_loss: 0.0196 - val_acc: 0.9946\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1064 - acc: 0.9557 - val_loss: 0.0205 - val_acc: 0.9943\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1041 - acc: 0.9550 - val_loss: 0.0205 - val_acc: 0.9948\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0989 - acc: 0.9575 - val_loss: 0.0194 - val_acc: 0.9953\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0982 - acc: 0.9572 - val_loss: 0.0189 - val_acc: 0.9948\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0968 - acc: 0.9562 - val_loss: 0.0181 - val_acc: 0.9950\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0938 - acc: 0.9587 - val_loss: 0.0185 - val_acc: 0.9951\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0944 - acc: 0.9582 - val_loss: 0.0175 - val_acc: 0.9952\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0938 - acc: 0.9576 - val_loss: 0.0191 - val_acc: 0.9951\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0917 - acc: 0.9578 - val_loss: 0.0203 - val_acc: 0.9936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8108c37dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "58277244-8f0c-4bef-9b96-fe5ebc056685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.019932233119336888, 0.9947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        },
        "outputId": "d1cf0c97-1888-481c-c656-4e923751814d"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model2 = Sequential()\n",
        " \n",
        "model2.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #26\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Convolution2D(32, 3, 3)) #24\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Convolution2D(10, 1, 1)) #22\n",
        "\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model2.add(Convolution2D(16, 3, 3))#9\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(16, 3, 3))#7\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(16, 3, 3))#5\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(16, 3, 3))#3\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(10, 4, 4))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utE2C8yYiL4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        },
        "outputId": "2e0faceb-5b47-48c0-8bde-fba03fc87cf9"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model2.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=20, verbose=1, validation_data=val_iterator, validation_steps=len(val_iterator), \n",
        "                    callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.6032 - acc: 0.8354 - val_loss: 0.1188 - val_acc: 0.9824\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.3437 - acc: 0.8851 - val_loss: 0.0594 - val_acc: 0.9910\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.3169 - acc: 0.8874 - val_loss: 0.0529 - val_acc: 0.9894\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.3006 - acc: 0.8909 - val_loss: 0.0374 - val_acc: 0.9933\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2873 - acc: 0.8944 - val_loss: 0.0375 - val_acc: 0.9920\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2839 - acc: 0.8942 - val_loss: 0.0349 - val_acc: 0.9921\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2867 - acc: 0.8930 - val_loss: 0.0298 - val_acc: 0.9928\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2812 - acc: 0.8943 - val_loss: 0.0298 - val_acc: 0.9936\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2770 - acc: 0.8967 - val_loss: 0.0291 - val_acc: 0.9927\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2762 - acc: 0.8962 - val_loss: 0.0288 - val_acc: 0.9935\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2734 - acc: 0.8976 - val_loss: 0.0247 - val_acc: 0.9945\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2684 - acc: 0.8986 - val_loss: 0.0262 - val_acc: 0.9937\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2651 - acc: 0.9000 - val_loss: 0.0251 - val_acc: 0.9935\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2681 - acc: 0.8987 - val_loss: 0.0243 - val_acc: 0.9937\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2704 - acc: 0.8980 - val_loss: 0.0251 - val_acc: 0.9937\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2689 - acc: 0.8988 - val_loss: 0.0267 - val_acc: 0.9930\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2685 - acc: 0.8988 - val_loss: 0.0230 - val_acc: 0.9943\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2621 - acc: 0.9021 - val_loss: 0.0249 - val_acc: 0.9932\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2641 - acc: 0.8999 - val_loss: 0.0249 - val_acc: 0.9938\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2605 - acc: 0.9014 - val_loss: 0.0223 - val_acc: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80ae0ad2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX97UVyfiiu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1179
        },
        "outputId": "f6fd2472-a7ae-4685-81d3-2c16823250c0"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.layers import Activation\n",
        "model3 = Sequential()\n",
        " \n",
        "model3.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), activation='relu', input_shape=(28,28,1))) #26\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Convolution2D(32, 3, 3, kernel_regularizer=l2(0.01), activation='relu')) #24\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model3.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), activation='relu'))#9\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model3.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), activation='relu'))#7\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model3.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), activation='relu'))#5\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model3.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), activation='relu'))#3\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model3.add(Convolution2D(10, 4, 4))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Activation('softmax'))\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwHHqtoZjxwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        },
        "outputId": "237c0ced-03ea-45f3-d397-cd7f77f050e7"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model3.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=20, verbose=1, validation_data=val_iterator, validation_steps=len(val_iterator), \n",
        "                    callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 13s 29ms/step - loss: 0.8116 - acc: 0.8494 - val_loss: 0.5387 - val_acc: 0.9208\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.3317 - acc: 0.9210 - val_loss: 0.1590 - val_acc: 0.9804\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2752 - acc: 0.9343 - val_loss: 0.1811 - val_acc: 0.9745\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2456 - acc: 0.9394 - val_loss: 0.1345 - val_acc: 0.9819\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2257 - acc: 0.9428 - val_loss: 0.1148 - val_acc: 0.9823\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2103 - acc: 0.9443 - val_loss: 0.0850 - val_acc: 0.9893\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1943 - acc: 0.9474 - val_loss: 0.0925 - val_acc: 0.9881\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1856 - acc: 0.9481 - val_loss: 0.1037 - val_acc: 0.9845\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1803 - acc: 0.9492 - val_loss: 0.0797 - val_acc: 0.9902\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1722 - acc: 0.9495 - val_loss: 0.0804 - val_acc: 0.9864\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1659 - acc: 0.9501 - val_loss: 0.0863 - val_acc: 0.9858\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1627 - acc: 0.9502 - val_loss: 0.0758 - val_acc: 0.9894\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1545 - acc: 0.9516 - val_loss: 0.0633 - val_acc: 0.9904\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1537 - acc: 0.9517 - val_loss: 0.0635 - val_acc: 0.9906\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.1459 - acc: 0.9528 - val_loss: 0.0624 - val_acc: 0.9894\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1443 - acc: 0.9535 - val_loss: 0.0584 - val_acc: 0.9911\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1431 - acc: 0.9532 - val_loss: 0.0590 - val_acc: 0.9915\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1406 - acc: 0.9537 - val_loss: 0.0602 - val_acc: 0.9911\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1379 - acc: 0.9530 - val_loss: 0.0511 - val_acc: 0.9937\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.1405 - acc: 0.9514 - val_loss: 0.0530 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80ae09c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXvMNHpNlIB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "2edd49e1-61be-4718-f9aa-3be6491db934"
      },
      "source": [
        "model_final = Sequential()\n",
        " \n",
        "model_final.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01), input_shape=(28,28,1))) #26\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "model_final.add(Convolution2D(32, 3, 3, kernel_regularizer=l2(0.01))) #24\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "model_final.add(Convolution2D(10, 1, 1)) #22\n",
        "\n",
        "model_final.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model_final.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01)))#9\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_final.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01)))#7\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_final.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01)))#5\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_final.add(Convolution2D(16, 3, 3, kernel_regularizer=l2(0.01)))#3\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_final.add(Convolution2D(10, 4, 4))\n",
        "model_final.add(BatchNormalization())\n",
        "model_final.add(Activation('relu'))\n",
        "model_final.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model_final.add(Flatten())\n",
        "model_final.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model_final.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg..., input_shape=(28, 28, 1...)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,604\n",
            "Trainable params: 16,360\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stC9RzyTlnkv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2722
        },
        "outputId": "8868ec23-6d69-48be-c821-761b9d347781"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model_final.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model_final.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=40, verbose=1, validation_data=val_iterator, validation_steps=len(val_iterator), \n",
        "                    callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.8402 - acc: 0.8329 - val_loss: 0.3808 - val_acc: 0.9378\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.4278 - acc: 0.8790 - val_loss: 0.2966 - val_acc: 0.9446\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3974 - acc: 0.8830 - val_loss: 0.1383 - val_acc: 0.9829\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3829 - acc: 0.8836 - val_loss: 0.1449 - val_acc: 0.9811\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3639 - acc: 0.8883 - val_loss: 0.1277 - val_acc: 0.9836\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3603 - acc: 0.8876 - val_loss: 0.1112 - val_acc: 0.9847\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.3480 - acc: 0.8899 - val_loss: 0.1076 - val_acc: 0.9849\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3361 - acc: 0.8932 - val_loss: 0.1069 - val_acc: 0.9827\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3389 - acc: 0.8911 - val_loss: 0.1108 - val_acc: 0.9838\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3338 - acc: 0.8909 - val_loss: 0.0879 - val_acc: 0.9884\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3305 - acc: 0.8914 - val_loss: 0.1447 - val_acc: 0.9713\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3218 - acc: 0.8934 - val_loss: 0.0850 - val_acc: 0.9882\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3279 - acc: 0.8910 - val_loss: 0.0705 - val_acc: 0.9922\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3158 - acc: 0.8950 - val_loss: 0.0676 - val_acc: 0.9911\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3111 - acc: 0.8956 - val_loss: 0.0688 - val_acc: 0.9898\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3051 - acc: 0.8978 - val_loss: 0.0714 - val_acc: 0.9897\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3124 - acc: 0.8945 - val_loss: 0.0638 - val_acc: 0.9912\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.3088 - acc: 0.8954 - val_loss: 0.0576 - val_acc: 0.9927\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3047 - acc: 0.8969 - val_loss: 0.0641 - val_acc: 0.9918\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3057 - acc: 0.8962 - val_loss: 0.0580 - val_acc: 0.9928\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2992 - acc: 0.8984 - val_loss: 0.0545 - val_acc: 0.9924\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3018 - acc: 0.8960 - val_loss: 0.0521 - val_acc: 0.9934\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.3016 - acc: 0.8971 - val_loss: 0.0591 - val_acc: 0.9911\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2954 - acc: 0.8994 - val_loss: 0.0657 - val_acc: 0.9881\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2985 - acc: 0.8973 - val_loss: 0.0590 - val_acc: 0.9916\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2929 - acc: 0.8989 - val_loss: 0.0629 - val_acc: 0.9904\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2969 - acc: 0.8969 - val_loss: 0.0552 - val_acc: 0.9919\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2964 - acc: 0.8973 - val_loss: 0.0479 - val_acc: 0.9944\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2937 - acc: 0.8977 - val_loss: 0.0474 - val_acc: 0.9936\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2931 - acc: 0.8983 - val_loss: 0.0550 - val_acc: 0.9919\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2951 - acc: 0.8971 - val_loss: 0.0483 - val_acc: 0.9937\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2887 - acc: 0.8991 - val_loss: 0.0479 - val_acc: 0.9933\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2881 - acc: 0.8996 - val_loss: 0.0475 - val_acc: 0.9941\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2857 - acc: 0.8996 - val_loss: 0.0483 - val_acc: 0.9926\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2897 - acc: 0.8989 - val_loss: 0.0503 - val_acc: 0.9927\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2890 - acc: 0.8979 - val_loss: 0.0421 - val_acc: 0.9941\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2884 - acc: 0.8990 - val_loss: 0.0493 - val_acc: 0.9926\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.2798 - acc: 0.9020 - val_loss: 0.0459 - val_acc: 0.9925\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2856 - acc: 0.8991 - val_loss: 0.0435 - val_acc: 0.9938\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.2863 - acc: 0.8994 - val_loss: 0.0457 - val_acc: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f80a49db4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prPmzr3_nur4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b5e74674-270b-4d9c-9845-295ea81cb468"
      },
      "source": [
        "results = model_final.evaluate_generator(val_iterator, steps=len(val_iterator), verbose=1)\n",
        "print(results)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 10ms/step\n",
            "[0.04536989903151989, 0.9937]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD_l8IGQoC5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1270
        },
        "outputId": "ada1f931-fdbe-4a41-b193-0a1ae54d8a9c"
      },
      "source": [
        "fig=plt.figure(figsize=(18, 16), dpi= 100, facecolor='w', edgecolor='k')\n",
        "predicted = model_final.predict_classes(X_test)\n",
        "correct_indices = np.nonzero(predicted == y_test)[0]\n",
        "incorrect_indices = np.nonzero(predicted != y_test)[0]\n",
        "\n",
        "for i, incorrect in enumerate(incorrect_indices[:25]):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\n",
        "      \"Pred {}, True: {}\".format(predicted[incorrect], \n",
        "                                       y_test[incorrect]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAATlCAYAAADcA/GyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncHgyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x1600 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBXG2IUsp-yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}